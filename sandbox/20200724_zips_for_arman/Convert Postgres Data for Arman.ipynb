{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Postgres Data for Arman\n",
    "\n",
    "Arman is requesting 2016 - 2018 (inclusive) data from `prj_volume.centreline_volumes`. This notebook downloads that data from Postgres, dumps it to zip files and checks its integrity. It's based off of `Convert Postgres Data for TEPs.ipynb`.\n",
    "\n",
    "Notebook was run on my laptop, under `/home/czhu/Data/GitHub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('./bdit_traffic_prophet/')\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import knowyourdata as kyd\n",
    "import zipfile\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from traffic_prophet import cfg\n",
    "import pathlib, os\n",
    "import configparser\n",
    "\n",
    "from traffic_prophet import connection\n",
    "from traffic_prophet.countmatch import reader\n",
    "\n",
    "defaultcolours = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "filepath = pathlib.Path.home().joinpath('.charlesconfig')\n",
    "if os.path.isfile(filepath):\n",
    "    vol_conn = connection.Connection(filepath, 'POSTGRES',\n",
    "                                     'czhu.btp_centreline_volumes')\n",
    "    ll_conn = connection.Connection(filepath, 'POSTGRES',\n",
    "                                    'czhu.btp_centreline_lonlat')\n",
    "    config = configparser.RawConfigParser()\n",
    "    config.read(filepath.as_posix())\n",
    "    MAPBOX_TOKEN = config['MAPBOX']['token']\n",
    "    PLOTLY_USER = config['PLOTLY']['user']\n",
    "    PLOTLY_KEY = config['PLOTLY']['key']\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffic_prophet.countmatch import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teps_dir = \"/mnt/c/Users/czhu5/Documents/VolumeModel/TEPs-I-EEDrun/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump data into zips\n",
    "\n",
    "### Find all centreline IDs (including HW401 ones) already in use in TEPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipsn = [teps_dir + \"PRTCS/negative/15min_counts_{0}.zip\".format(x)\n",
    "         for x in range(2006, 2017)]\n",
    "zipsp = [teps_dir + \"PRTCS/positive/15min_counts_{0}.zip\".format(x)\n",
    "         for x in range(2006, 2017)]\n",
    "zips = zipsn + zipsp\n",
    "rdr = reader.ReaderZip(zips)\n",
    "\n",
    "# Get HW401 centreline IDs\n",
    "re_centrelines = []\n",
    "\n",
    "for zf in rdr.source:\n",
    "    for c in rdr.get_zipreader(zf):\n",
    "        if 're' in c['filename']:\n",
    "            re_centrelines.append([c['filename'], c['centreline_id']])\n",
    "\n",
    "re_centreline_ids = list(set([x[1] for x in re_centrelines]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all centreline IDs in mid_f_point.csv\n",
    "df = pd.read_csv(teps_dir + \"PRTCS/negative/mid_f_point.csv\", header=None)\n",
    "midpoint_centerline_ids = list(df[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all centreline IDs in Landuse_pop_lane_speed.xlsx\n",
    "df = pd.read_excel(teps_dir + \"PRTCS/negative/locals/Landuse_pop_lane_speed.xlsx\")\n",
    "landuse_centreline_ids = list(df['centreline'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_teps_centreline_ids = list(\n",
    "    set(midpoint_centerline_ids).intersection(set(landuse_centreline_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReaderPostgresRaw(reader.ReaderBase):\n",
    "    \"\"\"Hacked method of accessing the raw 15-minute bin table from Postgres.\"\"\"\n",
    "\n",
    "    def get_pgreader(self, year):\n",
    "        with self.source.connect() as db_con:\n",
    "            sql_cmd = (\n",
    "                (\"SELECT centreline_id, dir_bin, count_bin, volume, count_type \"\n",
    "                 \"FROM {dbt} WHERE EXTRACT(year from count_bin) = {year} \"\n",
    "                 \"ORDER BY centreline_id, dir_bin, count_bin\")\n",
    "                .format(dbt=self.source.tablename,  year=year))\n",
    "\n",
    "            all_data = pd.read_sql(sql_cmd, db_con,\n",
    "                                   parse_dates=['count_bin', ])\n",
    "\n",
    "            for key, df in all_data.groupby(['centreline_id', 'dir_bin']):\n",
    "                centreline_id = key[0]\n",
    "                direction = key[1]\n",
    "\n",
    "                data = df[['count_bin', 'volume', 'count_type']].copy()\n",
    "                data.columns = ['Timestamp', '15-minute Volume', 'Count Type']\n",
    "                data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Filename is used to flag for HW401 data in Arman's zip files,\n",
    "                # so just pass a dummy value here.  Note that we can't use\n",
    "                # 'postgres' here since it contains 're'!\n",
    "                yield {'filename': 'fromPG',\n",
    "                       'centreline_id': int(centreline_id),\n",
    "                       'direction': int(direction),\n",
    "                       'data': data,\n",
    "                       'year': year}\n",
    "\n",
    "    def write_db_to_zip(self, year, fpath=\"./\"):\n",
    "        \"\"\"Writes a year's worth of 15 minute bins\"\"\"\n",
    "        rdr = self.get_pgreader(year)\n",
    "\n",
    "        fhzp = zipfile.ZipFile(\n",
    "            fpath + \"15min_counts_{0}_positive.zip\".format(year), 'w')\n",
    "        fhzn = zipfile.ZipFile(\n",
    "            fpath + \"15min_counts_{0}_negative.zip\".format(year), 'w')\n",
    "\n",
    "        for tc in rdr:\n",
    "            # Control sequence to prevent centreline_ids on HW401 and those with\n",
    "            # no land use data from being included in zip.\n",
    "            if tc['centreline_id'] in re_centreline_ids:\n",
    "                warnings.warn(\"{0} found in HW401 IDs!\".format(tc['centreline_id']))\n",
    "                continue\n",
    "            elif tc['centreline_id'] not in available_teps_centreline_ids:\n",
    "                warnings.warn(\"{0} doesn't have TEPs land use/geographic data!\".format(tc['centreline_id']))\n",
    "                continue\n",
    "\n",
    "            # Extract data from dict and convert it to TEPs format.\n",
    "            data = tc['data']\n",
    "            # Convert to DD-MMM-YYYY TT:TT:TT format favoured by Matlab.\n",
    "            data['Timestamp'] = data['Timestamp'].dt.strftime(r\"%d-%b-%Y %T\")\n",
    "            data['Nonsense'] = '999:9999999'\n",
    "            data['Centreline ID'] = tc['centreline_id']\n",
    "            data['Direction'] = tc['direction']\n",
    "            # Output to csv, but dump to string instead of file.\n",
    "            datastr = data[['Nonsense', 'Centreline ID', 'Direction',\n",
    "                            'Timestamp', '15-minute Volume', 'Count Type']].to_csv(\n",
    "                None, sep='\\t', na_rep='N/A', header=False, index=False)\n",
    "\n",
    "            filename = \"{0}_99999_{1}.txt\".format(tc['centreline_id'], year)\n",
    "            if tc['direction'] > 0:\n",
    "                fhzp.writestr(filename, datastr)\n",
    "            else:\n",
    "                fhzn.writestr(filename, datastr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump data from Postgres to zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgreader = ReaderPostgresRaw(vol_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgreader.write_db_to_zip(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgreader.write_db_to_zip(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgreader.write_db_to_zip(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/czhu/pythonenv/bditto/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: 439727 found in HW401 IDs!\n"
     ]
    }
   ],
   "source": [
    "pgreader.write_db_to_zip(2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data integrity\n",
    "\n",
    "To check if this data dump is consistent with the last one given to Arman (and the dump made in February 2020 to generate the 2018 GHG inventory for EED), created a few consistency check functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problem_counts(rdr_old, rdr_new):\n",
    "    \"\"\"Get problematic counts.\n",
    "\n",
    "    A problematic count is either a mismatch in daily count totals between\n",
    "    the old and new data, or data completely missing. Missing data is\n",
    "    denoted with NaNs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdr_old: reader.ReaderZip\n",
    "        Old daily counts.\n",
    "    rdr_new : reader.ReaderZip\n",
    "        New daily counts.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    problem_count : dict\n",
    "        Dictionary where keys are count locations (direction * centreline_id)\n",
    "        and values are tables of inconsistent or missing dat.\n",
    "    \n",
    "    \"\"\"\n",
    "    problem_counts = {}\n",
    "    ids_all = set(rdr_new.counts.keys()) | set(rdr_old.counts.keys())\n",
    "\n",
    "    for cid in ids_all:\n",
    "        if cid not in rdr_old.counts.keys():\n",
    "            merged = rdr_new.counts[cid].data[['Daily Count']].copy()\n",
    "            merged.rename(\n",
    "                columns={'Daily Count': \"Daily Count_new\"},\n",
    "                inplace=True)\n",
    "            merged['Daily Count_old'] = np.nan\n",
    "            problem_counts[cid] = merged\n",
    "        elif cid not in rdr_new.counts.keys():\n",
    "            merged = rdr_old.counts[cid].data[['Daily Count']].copy()\n",
    "            merged.rename(\n",
    "                columns={'Daily Count': \"Daily Count_old\"},\n",
    "                inplace=True)\n",
    "            merged['Daily Count_new'] = np.nan\n",
    "            problem_counts[cid] = merged\n",
    "        else:\n",
    "            merged = pd.merge(rdr_old.counts[cid].data[['Daily Count']],\n",
    "                              rdr_new.counts[cid].data[['Daily Count']], how='outer',\n",
    "                              left_index=True, right_index=True, suffixes=('_old', '_new'))\n",
    "            notclose = ~np.isclose(merged[\"Daily Count_old\"],\n",
    "                                   merged[\"Daily Count_new\"], atol=1e-10, rtol=1e-4)\n",
    "            if np.sum(notclose):\n",
    "                problem_counts[cid] = merged.loc[notclose, :].copy()\n",
    "    \n",
    "    return problem_counts\n",
    "\n",
    "\n",
    "def get_mismatch_count(df):\n",
    "    return np.sum(df.isnull().values), 2. * df.dropna().shape[0]\n",
    "\n",
    "\n",
    "def get_mismatch_fraction(rdr_old, rdr_new, problem_counts):\n",
    "    \"\"\"Get the mismatch fraction.\n",
    "    \n",
    "    The mismatch fraction is the fraction of all lines in either rdr_old\n",
    "    or rdr_new that are unique to that dataset. This can either be because\n",
    "    the count is different between the two datasets, or because it is\n",
    "    completely missing.\n",
    "    \n",
    "    \"\"\"\n",
    "    return (sum([sum(get_mismatch_count(x)) for x in problem_counts.values()]) /\n",
    "            (sum([x.data.shape[0] for x in rdr_old.counts.values()]) +\n",
    "             sum([x.data.shape[0] for x in rdr_new.counts.values()])))\n",
    "\n",
    "\n",
    "def get_mismatch_breakdown(rdr_old, rdr_new, problem_counts):\n",
    "    \"\"\"Get the breakdown of mismatch count by type.\n",
    "\n",
    "    Counts the total number of missing and inconsistent entries.\n",
    "\n",
    "    \"\"\"\n",
    "    mismatches = np.array([get_mismatch_count(x)\n",
    "                           for x in problem_counts.values()])\n",
    "    return mismatches.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in old data.\n",
    "rdr_old = reader.ReaderZip(\"/mnt/c/Users/czhu5/Documents/VolumeModel/TEPs-I-EEDrun/PRTCS/negative/15min_counts_2017.zip\")\n",
    "rdr_old.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdr_new = reader.ReaderZip(\"./15min_counts_2017_negative.zip\")\n",
    "rdr_new.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many centreline IDs are in the new data but not the old?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rdr_new.counts.keys()) - set(rdr_old.counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many centreline IDs are in the old data but not the new?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-20050749,\n",
       " -14203393,\n",
       " -14047336,\n",
       " -13515818,\n",
       " -8203281,\n",
       " -3994385,\n",
       " -2884350,\n",
       " -441581,\n",
       " -440741,\n",
       " -9437}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rdr_old.counts.keys()) - set(rdr_new.counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're missing a number of counts that are no longer available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_counts = get_problem_counts(rdr_old, rdr_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([-30023559, -6868868, -913249, -909146, -20037402, -20164356, -913152, -1146615, -1146568, -7929516, -14659244, -1146507, -8322682, -8351286, -13975074, -1146358, -1146335, -445884, -14011679, -908543, -7416, -441581, -908449, -445532, -30010427, -12336171, -13515818, -12336156, -8203281, -445309, -1141572, -30087992, -30087988, -30018291, -14662366, -11070091, -1145405, -14203393, -1145317, -113111, -30022069, -440741, -1145215, -1141002, -13969576, -14047336, -444497, -444412, -1978, -440202, -20080518, -440171, -444264, -12334941, -12334937, -1841, -443987, -443975, -14177858, -12334629, -12334583, -6837741, -30012667, -1144036, -9437, -107733, -14255077, -30040979, -890, -8754031, -6853472, -20050749, -30016282, -9212691, -3994385, -2884350, -10834665, -20140757, -20050591, -1147466, -1147434, -20054568, -442915, -1147406, -1147347, -913864, -8540609, -8352168, -1147258, -30003565, -1147201, -106797, -10133796, -30011654, -1147135, -1147113, -30036166, -1146997, -14073969, -4030552, -442447])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of lines with mismatches: 2.454%\n"
     ]
    }
   ],
   "source": [
    "mismatch_frac = get_mismatch_fraction(rdr_old, rdr_new, problem_counts)\n",
    "\n",
    "print(f\"Percentage of lines with mismatches: {mismatch_frac * 100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 924.0; inconsistent values: 0.0\n"
     ]
    }
   ],
   "source": [
    "mismatch_break = get_mismatch_breakdown(rdr_old, rdr_new, problem_counts)\n",
    "\n",
    "print(f\"Missing values: {mismatch_break[0]:0.1f}; inconsistent values: {mismatch_break[1]:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 924 values missing in the current data dump that were available back in February - this represents around 2.4% of all data. No daily counts available in both datasets have values inconsistent from one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2016 data\n",
    "\n",
    "Now we take a look at 2016 data, comparing the original data processed into a zip file by Arman with the one we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdr_old = reader.ReaderZip(\"/mnt/c/Users/czhu5/Documents/VolumeModel/TEPs-I-EEDrun/PRTCS/negative/15min_counts_2016.zip\")\n",
    "rdr_old.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdr_new = reader.ReaderZip(\"./15min_counts_2016_negative.zip\")\n",
    "rdr_new.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-30075992,\n",
       " -30073995,\n",
       " -30073908,\n",
       " -30070016,\n",
       " -30013725,\n",
       " -30008185,\n",
       " -20142356,\n",
       " -14675961,\n",
       " -14674278,\n",
       " -14673213,\n",
       " -14672915,\n",
       " -14624107,\n",
       " -14230112,\n",
       " -14184390,\n",
       " -14063147,\n",
       " -14037577,\n",
       " -14037514,\n",
       " -14037155,\n",
       " -14035998,\n",
       " -14035996,\n",
       " -14025568,\n",
       " -14025469,\n",
       " -14025284,\n",
       " -14024688,\n",
       " -14020124,\n",
       " -14013502,\n",
       " -14013481,\n",
       " -14003891,\n",
       " -13323711,\n",
       " -13297428,\n",
       " -12102593,\n",
       " -11774649,\n",
       " -11714744,\n",
       " -11631428,\n",
       " -11273041,\n",
       " -11272989,\n",
       " -11226820,\n",
       " -10877626,\n",
       " -10864309,\n",
       " -10864277,\n",
       " -10516346,\n",
       " -10486145,\n",
       " -10475569,\n",
       " -10223667,\n",
       " -10222712,\n",
       " -10010771,\n",
       " -9234036,\n",
       " -9212691,\n",
       " -9085798,\n",
       " -8771611,\n",
       " -8677261,\n",
       " -8677227,\n",
       " -8676918,\n",
       " -8676871,\n",
       " -8676863,\n",
       " -8676772,\n",
       " -8491783,\n",
       " -8457366,\n",
       " -8457323,\n",
       " -8457317,\n",
       " -8457315,\n",
       " -8344825,\n",
       " -8155563,\n",
       " -8067830,\n",
       " -8033769,\n",
       " -7930670,\n",
       " -7930588,\n",
       " -7929673,\n",
       " -7762785,\n",
       " -7204482,\n",
       " -7009490,\n",
       " -6624394,\n",
       " -6619735,\n",
       " -5868170,\n",
       " -4570674,\n",
       " -4429233,\n",
       " -3369829,\n",
       " -3369767,\n",
       " -3065754,\n",
       " -3065748,\n",
       " -2884227,\n",
       " -1147466,\n",
       " -1146683,\n",
       " -1146332,\n",
       " -1146204,\n",
       " -1146057,\n",
       " -1145856,\n",
       " -1145855,\n",
       " -1145635,\n",
       " -1145433,\n",
       " -1145317,\n",
       " -1145316,\n",
       " -1145286,\n",
       " -1145285,\n",
       " -1143977,\n",
       " -1139498,\n",
       " -914317,\n",
       " -441121,\n",
       " -439183,\n",
       " -436769,\n",
       " -111979,\n",
       " -109553,\n",
       " -109416,\n",
       " -109415,\n",
       " -108322,\n",
       " -107831,\n",
       " -107766,\n",
       " -107745,\n",
       " -105192,\n",
       " -104923,\n",
       " -104675,\n",
       " -104586}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rdr_new.counts.keys()) - set(rdr_old.counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-30073941,\n",
       " -30066680,\n",
       " -14663487,\n",
       " -13502340,\n",
       " -13502069,\n",
       " -7941494,\n",
       " -5101256,\n",
       " -910041,\n",
       " -909609,\n",
       " -909292,\n",
       " -908665,\n",
       " -908251,\n",
       " -908165,\n",
       " -908093,\n",
       " -908081,\n",
       " -908053,\n",
       " -445781,\n",
       " -445695,\n",
       " -445177,\n",
       " -445162,\n",
       " -444895,\n",
       " -444632,\n",
       " -444620,\n",
       " -444602,\n",
       " -444010,\n",
       " -443777,\n",
       " -443687,\n",
       " -443397,\n",
       " -443225,\n",
       " -443129,\n",
       " -443125,\n",
       " -442793,\n",
       " -442619,\n",
       " -442118,\n",
       " -441560,\n",
       " -439181,\n",
       " -439159,\n",
       " -438928,\n",
       " -438892,\n",
       " -438841,\n",
       " -437972,\n",
       " -108420,\n",
       " -108404,\n",
       " -108373,\n",
       " -108276,\n",
       " -108252,\n",
       " -107655,\n",
       " -107645,\n",
       " -106873,\n",
       " -106799,\n",
       " -105318}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rdr_old.counts.keys()) - set(rdr_new.counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_counts = get_problem_counts(rdr_old, rdr_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([-1145856, -1145855, -1022, -444412, -14675961, -30066680, -109553, -14024688, -909292, -14255077, -908251, -14184390, -12102593, -14664635, -1978, -3065754, -3065748, -30040979, -439183, -914317, -8677261, -439181, -440202, -30023559, -20080518, -108420, -13502340, -908165, -445309, -890, -10516346, -30008185, -439159, -108404, -440171, -8677227, -10948456, -109416, -109415, -444264, -3369829, -9085798, -7762785, -6853472, -14025568, -105318, -12334941, -12334937, -443225, -108373, -12334931, -441170, -11273041, -7929673, -1141572, -11631428, -14663487, -908093, -1146683, -9109303, -30087988, -908081, -7930670, -1139498, -3369767, -1145635, -108322, -441121, -11272989, -20037402, -30016282, -908053, -13297428, -9212691, -13503251, -913167, -8491783, -442118, -20164356, -446207, -14025469, -443129, -445177, -1146615, -8067830, -443125, -108276, -445162, -105192, -13503206, -1142500, -14303970, -8491741, -7930588, -108252, -910041, -906966, -20140757, -437972, -1146568, -5101256, -11226820, -3111616, -20102845, -106171, -10877626, -11774649, -11046582, -10864309, -14003891, -14659244, -10864277, -438928, -5868170, -2884227, -7204482, -13502069, -9234036, -438892, -444010, -14230112, -1145433, -6619735, -443987, -4223571, -1147466, -14037577, -443975, -14673478, -14025284, -1145406, -1145405, -438841, -8676918, -4570674, -14063147, -1147434, -20054568, -12334629, -9383460, -442915, -436769, -13975074, -14020124, -13975065, -1147406, -14037514, -8676871, -14203393, -8676863, -12334583, -1146358, -6837741, -8033769, -1145317, -1145316, -1146335, -444895, -1146332, -104923, -440789, -7062996, -1147347, -442831, -913864, -1145286, -1145285, -13323711, -445884, -444854, -14171574, -30022069, -439730, -4429233, -8155563, -442793, -8676772, -30008718, -10486145, -443777, -106873, -7941494, -908665, -30003565, -111979, -14624107, -1146214, -14674278, -12387683, -1147234, -1146204, -1146202, -5413210, -445781, -9278804, -1147201, -436544, -14673213, -107831, -1147184, -106799, -909609, -443687, -10133796, -30013725, -20142356, -1141002, -30070016, -445695, -442619, -8344825, -107766, -1144036, -104675, -107745, -14663902, -444637, -441560, -444632, -7009490, -30004432, -444620, -1146057, -1141960, -30036166, -444602, -11714744, -112815, -1143977, -13969576, -14037155, -8457366, -10010771, -30073995, -104586, -6624394, -107655, -107645, -14174332, -10222712, -1146997, -10575986, -14073969, -8457323, -8457317, -8457315, -8237152, -445532, -30075992, -30073941, -444497, -442447, -30075982, -14013502, -30073908, -10223667, -10475569, -1146926, -12336171, -14013481, -14035998, -12336156, -8771611, -14035996, -12336151, -14672915, -440332, -30019594, -443397, -10010625])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of lines with mismatches: 31.126%\n"
     ]
    }
   ],
   "source": [
    "mismatch_frac = get_mismatch_fraction(rdr_old, rdr_new, problem_counts)\n",
    "\n",
    "print(f\"Percentage of lines with mismatches: {mismatch_frac * 100:0.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: 18185.0; inconsistent values: 0.0\n"
     ]
    }
   ],
   "source": [
    "mismatch_break = get_mismatch_breakdown(rdr_old, rdr_new, problem_counts)\n",
    "\n",
    "print(f\"Missing values: {mismatch_break[0]:0.1f}; inconsistent values: {mismatch_break[1]:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of missing values! No inconsistent ones, which is another clue that what we're looking at is missing data either in the old data or the new.\n",
    "\n",
    "Here's one example of new data that's missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Daily Count_old</th>\n",
       "      <th>Daily Count_new</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Day of Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">2016</th>\n",
       "      <th>1</th>\n",
       "      <td>37267.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>43231.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>40023.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>28850.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>43884.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>41700.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>41597.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>37229.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>38195.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>41930.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>43094.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>39043.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>31772.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>32382.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>42461.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>38358.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Daily Count_old  Daily Count_new\n",
       "Year Day of Year                                  \n",
       "2016 1                    37267.0              NaN\n",
       "     10                   43231.0              NaN\n",
       "     136                  40023.0              NaN\n",
       "     157                  28850.0              NaN\n",
       "     236                  43884.0              NaN\n",
       "     238                  41700.0              NaN\n",
       "     240                  41597.0              NaN\n",
       "     241                  37229.0              NaN\n",
       "     242                  38195.0              NaN\n",
       "     243                  41930.0              NaN\n",
       "     246                  43094.0              NaN\n",
       "     247                  39043.0              NaN\n",
       "     248                  31772.0              NaN\n",
       "     249                  32382.0              NaN\n",
       "     250                  42461.0              NaN\n",
       "     251                  38358.0              NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_counts[-30003565]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Daily Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Day of Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">2016</th>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>45397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>43970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>54155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>58119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>60504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>66925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>70376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>69778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>72915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>66976.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  Daily Count\n",
       "Year Day of Year                        \n",
       "2016 2           2016-01-02      45397.0\n",
       "     3           2016-01-03      43970.0\n",
       "     4           2016-01-04      54155.0\n",
       "     5           2016-01-05      58119.0\n",
       "     6           2016-01-06      60504.0\n",
       "...                     ...          ...\n",
       "     277         2016-10-03      66925.0\n",
       "     278         2016-10-04      70376.0\n",
       "     279         2016-10-05      69778.0\n",
       "     280         2016-10-06      72915.0\n",
       "     281         2016-10-07      66976.0\n",
       "\n",
       "[223 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdr_new.counts[-30003565].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Daily Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Day of Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">2016</th>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>37267.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>45397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>43970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>54155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>58119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>66925.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>70376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>69778.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>72915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>66976.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  Daily Count\n",
       "Year Day of Year                        \n",
       "2016 1           2016-01-01      37267.0\n",
       "     2           2016-01-02      45397.0\n",
       "     3           2016-01-03      43970.0\n",
       "     4           2016-01-04      54155.0\n",
       "     5           2016-01-05      58119.0\n",
       "...                     ...          ...\n",
       "     277         2016-10-03      66925.0\n",
       "     278         2016-10-04      70376.0\n",
       "     279         2016-10-05      69778.0\n",
       "     280         2016-10-06      72915.0\n",
       "     281         2016-10-07      66976.0\n",
       "\n",
       "[239 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdr_old.counts[-30003565].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually confirmed that `prj_volume.centreline_volumes` does not have any data for `30003565` on January 2, so this is truly missing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
